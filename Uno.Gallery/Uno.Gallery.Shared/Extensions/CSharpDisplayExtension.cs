using System;
using System.Collections.Generic;
using System.Text;
using System.Text.RegularExpressions;

namespace Uno.Gallery.Extensions
{
	/// <summary>
	/// Mutually execulsive Type of token generated by Tokenizer
	/// </summary>
	public enum TokenType
	{
		Comment,
		Number,
		String,
		Operator,
		Delimiter,
		Keyword,
		Builtins,
		WhiteSpace,
		Identifier,
		Unknown,
	}

	/// <summary>
	/// Meaning full characters span
	/// </summary>
	public class Token
	{
		public Token(int startIndex, int length, TokenType type)
		{
			StartIndex = startIndex;
			Length = length;
			Type = type;
		}

		public TokenType Type { get; private set; }

		public int StartIndex { get; private set; }

		public int Length { get; private set; }
	}

	public class LexicalRule
	{
		public TokenType Type { get; set; }

		public Regex RegExpression { get; set; }

		private static string BuildRegex(params string[] words)
		{
			return "^((" + string.Join(")|(", words) + "))\\b";
		}

		public static Regex WordRegex(params string[] words)
		{
			return new Regex(BuildRegex(words));
		}

		public static Regex WordRegexCaseInsensitive(params string[] words)
		{
			return new Regex(BuildRegex(words), RegexOptions.IgnoreCase);
		}
	}

	public interface IGrammar
	{
		string Name { get; }

		List<LexicalRule> Rules { get; }
	}

	public class Tokenizer
	{
		public Tokenizer(IGrammar grammar)
		{
			Grammar = grammar;
		}

		public IGrammar Grammar { get; private set; }

		public IEnumerable<Token> Tokenize(string script)
		{
			int i = 0;
			int length = script.Length;

			Match match;
			var builder = new StringBuilder(script);

			string str = script;

			while (i < length)
			{
				foreach (var rule in Grammar.Rules)
				{
					match = rule.RegExpression.Match(str);

					if (match.Success)
					{
						if (match.Length == 0)
						{
							throw new Exception(string.Format("Regex match length is zero. This can lead to infinite loop. Please modify your regex {0} for {1} so that it can't match character of zero length", rule.RegExpression, rule.Type));
						}

						yield return new Token(i, match.Length, rule.Type);
						i += match.Length;

						builder.Remove(0, match.Length);
						break;
					}
				}

				str = builder.ToString();
			}
		}
	}

	public enum HighlightLanguages
	{
		PlainText,
		CSharp
		//JavaScript,
		//Python,
		//XML,
		//JSON,
		//SQL,
		//PHP,
		//Ruby,
		//CPlusPlus,
		//CSS,
		//Java,
	}

	public class CSharpGrammar : IGrammar
	{
		public CSharpGrammar()
		{
			Rules = new List<LexicalRule>()
			{
                // Single line comment
                new LexicalRule()
				{
					Type = TokenType.Comment,
					RegExpression = new Regex("^(\\/\\/\\/?[^\r\n]*)"),
				},

                // Multi line comment
                new LexicalRule()
				{
					Type = TokenType.Comment,
					RegExpression = new Regex("^\\/\\*(\\*(?!\\/)|[^*])*\\*\\/"),
				},

                // String Marker
                new LexicalRule()
				{
					Type = TokenType.String,
					RegExpression = new Regex("^([@|$]\"(?:[^\"]|\"\")*\"|\"(?:\\.|[^\\\"])*(\"|\\b))", RegexOptions.IgnoreCase),
				},

                // Char Marker
                new LexicalRule()
				{
					Type = TokenType.String,
					RegExpression = new Regex("^('(\\w\\d){1}')", RegexOptions.IgnoreCase),
				},

                // Numbers
                new LexicalRule()
				{
					Type = TokenType.Number,
					RegExpression = new Regex("^\\d+(((\\.)|(x))\\d*)?"),
				},

                // Literals
                new LexicalRule()
				{
					Type = TokenType.Number,
					RegExpression = LexicalRule.WordRegex(
						"true",
						"false",
						"null"
					),
				},

                // Whitespace
                new LexicalRule()
				{
					Type = TokenType.WhiteSpace,
					RegExpression = new Regex("^\\s"),
				},

                // Single Char Operator
                new LexicalRule()
				{
					Type = TokenType.Operator,
					RegExpression = new Regex("^[\\+\\-\\*/%&|\\^~<>!]"),
				},

                // Double character comparison operators
                new LexicalRule()
				{
					Type = TokenType.Operator,
					RegExpression = new Regex("^((==)|(!=)|(<=)|(>=)|(<<)|(>>>?)|(//)|(\\*\\*))"),
				},

                // Single Delimiter
                new LexicalRule()
				{
					Type = TokenType.Delimiter,
					RegExpression = new Regex("^[\\(\\)\\[\\]\\{\\}@,:`=;\\.]"),
				},

                // Double Char Operator
                new LexicalRule()
				{
					Type = TokenType.Delimiter,
					RegExpression = new Regex("^((\\+=)|(\\-=)|(\\*=)|(%=)|(/=)|(\\++)|(\\--))"),
				},

                // Triple Delimiter
                new LexicalRule()
				{
					Type = TokenType.Delimiter,
					RegExpression = new Regex("^((//=)|(>>=)|(<<=)|(\\*\\*=))"),
				}, 

                // Keywords
                new LexicalRule()
				{
					Type = TokenType.Keyword,
					RegExpression = LexicalRule.WordRegex(
						"abstract",
						"as",
						"base",
						"bool",
						"break",
						"byte",
						"case",
						"catch",
						"char",
						"checked",
						"class",
						"const",
						"continue",
						"decimal",
						"default",
						"delegate",
						"do",
						"double",
						"else",
						"enum",
						"event",
						"explicit",
						"extern",
						"finally",
						"fixed",
						"float",
						"for",
						"foreach",
						"goto",
						"if",
						"implicit",
						"in",
						"int",
						"interface",
						"internal",
						"is",
						"lock",
						"long",
						"namespace",
						"new",
						"object",
						"operator",
						"out",
						"override",
						"params",
						"private",
						"protected",
						"public",
						"readonly",
						"ref",
						"return",
						"sbyte",
						"sealed",
						"short",
						"sizeof",
						"stackalloc",
						"static",
						"string",
						"struct",
						"switch",
						"this",
						"throw",
						"try",
						"typeof",
						"uint",
						"ulong",
						"unchecked",
						"unsafe",
						"ushort",
						"using",
						"void",
						"volatile",
						"while",
						"set",
						"get",
						"value",
						"await",
						"async",
						"yield",
						"var",
						"partial"
					),
				},

                // Commonly-used classes (usually part of `System` namespace)
                new LexicalRule() {
					Type = TokenType.Builtins,
					RegExpression = LexicalRule.WordRegex(
						"Boolean",
						"Byte",
						"Console",
						"SByte",
						"Char",
						"Decimal",
						"Double",
						"Enum",
						"Single",
						"Int32",
						"UInt32",
						"Int64",
						"UInt64",
						"Object",
						"Int16",
						"UInt16",
						"String",
						"StringBuilder",
						"Exception",
						"Guid",
						"DateTime",
						"DateTimeOffset",
						"TimeSpan",
						"Uri",
						"UriKind",
						"Dictionary",
						"List",
						"ObservableCollection",
						"DelegateCommand",
						"ICommand",
						"RelayCommand",
						"AsyncCommand",
						"RaisePropertyChanged",
						"ToString",
						"Task",
						"virtual",
						"IList",
						"IEnumerable",
						"ICollection",
						"Nullable",
						"BitmapImage",
						"Image",
						"VirtualKey",
						"StringComparison",
						"Type",
						"ArgumentException",
						"EventHandler",
						"Clipboard",
						"KeyValuePair",
						"Convert",
						"DependencyProperty",
						"Json",
						"File",
						"Path",
						"Window"
					),
				},

                // Identifiers
                new LexicalRule ()
				{
					Type = TokenType.Identifier,
					RegExpression = new Regex("^[_A-Za-z][_A-Za-z0-9]*")
				},
                
                // Any
                new LexicalRule()
				{
					Type = TokenType.Unknown,
					RegExpression = new Regex("^."),
				},
			};

		}

		public string Name
		{
			get
			{
				return "C#";
			}
		}

		public List<LexicalRule> Rules { get; private set; }
	}
}
